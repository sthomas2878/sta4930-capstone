<HEADLINE>
Кто должен решать, какие решения принимать алгоритмам?
<P>
КЕМБРИДЖ – В течение последних нескольких лет в исследовании “Moral Machine”, проводимом Массачусетским технологическим институтом, были изучены общественные предпочтения относительно того, как приложения искусственного интеллекта должны вести себя в различных ситуациях.
Один из выводов из этих данных заключается в том, что когда автономное транспортное средство (AV) сталкивается со сценарием “жизнь или смерть”, то, как, по некоторому мнению, оно должно среагировать во многом зависит от того, где оно произведено и от того, что оно знает о вовлеченных пешеходах или пассажирах.
<P>
Following its targeted killing of Iran's second most powerful leader, the US could well find itself with no alternative but to devote more military resources to the Middle East, a path that could lead to additional Iranian provocations.
And that shift would occur at a time of growing challenges to US interests elsewhere in the world.
<P>
The targeted killing by the United States of one of Iran's top military leaders represents a significant symbolic defeat for the Iranian regime, but it does not augur all-out war.
After all, Iran and the US have already been at war for decades, and neither side has an interest in an uncontrolled military escalation now.
<P>
As in previous years, Project Syndicate asked its commentators to offer their best guesses about the events and trends that will define the coming 12 months.
If there is one common theme in this year's selection, it is that what happens in 2020 will weigh on the present for many years to come.
<P>
Например, в AV-версии классической “проблемы вагонетки”, некоторые могли бы предпочесть, чтобы машина ударила осужденного за убийство, прежде чем причинить вред другим, или чтобы она сбила пожилого человека, а не ребенка.
Третьи могли бы утверждать, что AV должно просто рискнуть, чтобы избежать дискриминации на основе фактических данных.
<P>
Как правило, такие затруднительные ситуации зарезервированы для залов судебных заседаний или полицейских расследований постфактум.
Но в случае с AV, выбор будет сделан в течение нескольких миллисекунд, а этого времени недостаточно для принятия обоснованного решения.
Важно не то, что знаем мы, а то, что знает машина.
Вопрос в том, какая информация должна быть заложена в AV об окружающих их людях.
И надо ли предоставлять фирмам возможность предлагать различные этические системы для достижения конкурентного преимущества?
<P>
Рассмотрим следующий сценарий: автомобиль из Китая имеет заводские стандарты, отличные от автомобилей, произведенных в США, но поставляется и используется на территории США.
Эти автомобили китайского производства и американского производства движутся к неизбежному столкновению.
Какая система должна преобладать, если водитель китайского автомобиля имеет этические предпочтения, отличные от водителя американского автомобиля?
<P>
Помимо культурных различий в этических предпочтениях, необходимо учитывать различия в данных положений из разных стран.
Например, автомобиль китайского производства может иметь доступ к данным социальной оценки, что позволяет его алгоритму принятия решений включать дополнительные ресурсы, которые недоступны для американских автопроизводителей.
Более полные данные могли бы привести к лучшим, более последовательным решениям, но должно ли это преимущество позволить одной системе отвергать другую?
<P>
Очевидно, что прежде чем AV массово выйдут на дорогу, мы должны будем определить, на ком лежит ответственность за принятие алгоритмических решений, будь то муниципальные власти, национальные правительства или многосторонние учреждения.
Более того, нам понадобятся новые рамки для управления этим пересечением бизнеса и государства.
Проблема заключается не только в том, как поведет себя AV в экстремальных ситуациях, но и в том, как компании будут взаимодействовать с различными культурами при разработке и внедрении алгоритмов принятия решений.
<P>
Несложно представить, что все производители AV просто будут рекламировать этические системы, которые ценят жизнь водителя превыше всего, или которые позволяют пользователю переключать свои собственные этические настройки.
Чтобы предотвратить эту “трагедию общих ресурсов”, необходимы рамки для установления связи и координации решений между AV.
Но при разработке таких систем в разных культурных контекстах, директивные органы и предприятия столкнутся с различными культурными представлениями о суверенитете, конфиденциальности и индивидуальной автономии.
<P>
Это создает дополнительные проблемы, поскольку системы ИИ не терпят двусмысленности.
Разработка ИИ-приложения с нуля требует глубокой специфики; хорошо это или плохо, но эти системы делают только то, что вы им говорите.
Это означает, что фирмам, правительствам и другим поставщикам услуг придется делать однозначный выбор при кодировании протоколов реагирования для различных ситуаций.
<P>
Тем не менее, прежде чем это произойдет, директивным органам необходимо будет установить сферу алгоритмической ответственности, чтобы определить, какие решения, если таковые имеются, должны быть оставлены на усмотрение компаний или отдельных лиц. Те, что находятся в ведении государства, должны быть обсуждены.
И учитывая, что на этические и моральные вопросы нет простых ответов, вряд ли можно достичь консенсуса.
За исключением окончательного решения, нам нужно будет создать системы, которые, по крайней мере, облегчат связь между AV и рассудят алгоритмические споры и дорожные происшествия.
<P>
Учитывая необходимость конкретизации при разработке алгоритмов принятия решений, само собой разумеется, что будет необходим международный орган для установления стандартов, в соответствии с которыми решаются моральные и этические дилеммы.
В конце концов AV, являются лишь одним из приложений алгоритмического принятия решений.
Заглядывая вперед, стандарты алгоритмической ответственности должны будут управляться во многих областях.
<P>
В конечном счете, первый вопрос, который нам надлежит решить, имеют ли фирмы право разрабатывать альтернативные этические рамки для принятия алгоритмических решений.
Мы утверждаем, что у них этого права нет.
<P>
В эпоху ИИ, некоторые компоненты глобальных производственно-сбытовых цепочек в конечном итоге будут автоматизированы как само собой разумеющееся, и с этого момента они больше не будут рассматриваться в качестве областей, в которых компании могут добиться конкурентного преимущества.
Процесс определения и вынесения решения по алгоритмической ответственности должен стать одной из таких областей.
Так или иначе, решения будут приняты.
Лучше, чтобы по ним было принято единое решение и как можно более демократично.
