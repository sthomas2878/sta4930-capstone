<HEADLINE>
Являются ли технологии новой границей для устойчивого развития?
<P>
ПАРИЖ – Обсуждения “устойчивости” как правило, по вполне понятным причинам, сосредоточены на экологических и социальных обязательствах компаний.
Но финансовый сектор, в частности, должен учитывать два других, менее очевидных аспекта устойчивости.
Регуляторная устойчивость имеет важное значение для устранения системного риска, который для наших обществ представляет финансовый сектор.
Кроме того, появляющаяся новая граница технологической устойчивости оказывает все большее влияние на бизнес-модели и стратегии.
<P>
Following its targeted killing of Iran's second most powerful leader, the US could well find itself with no alternative but to devote more military resources to the Middle East, a path that could lead to additional Iranian provocations.
And that shift would occur at a time of growing challenges to US interests elsewhere in the world.
<P>
The targeted killing by the United States of one of Iran's top military leaders represents a significant symbolic defeat for the Iranian regime, but it does not augur all-out war.
After all, Iran and the US have already been at war for decades, and neither side has an interest in an uncontrolled military escalation now.
<P>
As in previous years, Project Syndicate asked its commentators to offer their best guesses about the events and trends that will define the coming 12 months.
If there is one common theme in this year's selection, it is that what happens in 2020 will weigh on the present for many years to come.
<P>
Данные, робототехника и искусственный интеллект сегодня у всех на устах.
Но несмотря на то, что эти новые технологии обладают огромным потенциалом, финансовые институты также должны понимать связанные с ними риски, социальные и этические последствия.
<P>
Что касается данных, цифры поражают: 90% всех данных в мире были созданы за последние два года, и мы генерируем примерно 2,5 квинтиллиона байт каждый день.
В этом контексте важно, чтобы финансовые институты, являющиеся как основными производителями, так и пользователями данных, решали вопросы по созданию и защите данных.
<P>
Нормативные акты в этой области становятся все более жесткими, что подтверждает Общий регламент Европейского союза по защите данных (GDPR).
К счастью, банки и страховые компании продолжают пользоваться репутацией заслуживающей доверия.
Их задача состоит в том, чтобы уважать и поддерживать это доверие, несмотря на растущий соблазн монетизировать свои “активы” данных путем их продажи или использования в маркетинговых целях.
<P>
Тем временем, робототехника трансформирует все отрасли и рынок труда.
По некоторым оценкам, в течение следующего десятилетия от одной четверти до половины всей рабочей силы финансового сектора могут быть заменены роботами и ИИ.
Правда, исследования немецких рабочих производственных отраслей не нашли доказательств того, что роботы сокращают общую занятость: хотя каждый робот ликвидирует два производственных рабочих места, он создает дополнительные рабочие места в сфере обслуживания, которые полностью компенсируют эту потерю.
Но роботы влияют на структуру совокупной занятости.
<P>
Фактически, мы, вероятно, переживаем еще один эпизод “созидательного разрушения” Шумпетера.
Робототехника и ИИ изменят типы предлагаемых рабочих мест, их местоположение и навыки, необходимые для их заполнения.
Этот разрушительный эффект должен тщательно регулироваться.
Поэтому банки и другие финансовые институты должны сосредоточиться на том, чтобы предвидеть влияние этих технологий на своих сотрудников, и вкладывать средства в обучение и профориентацию, чтобы помочь им в переходный период.
<P>
Технологии ИИ, вероятно, наиболее трудные для финансового сектора из-за их сложности и этических последствий.
Несмотря на то, что со времени мирового финансового кризиса, финансовые институты подвергаются критике, в действительности они давно учитывают этические аспекты.
Но с ИИ мы переходим на другой уровень, где фирмы должны предвидеть потенциальные этические риски и определять механизмы для обеспечения контроля и подотчетности.
<P>
Следует выделить две основные проблемы.
Первая – это смещение алгоритма (или смещение ИИ), которое возникает, когда алгоритм систематически выдает искаженные результаты из-за ошибочных допущений в процессе машинного обучения.
Например, в 2014 году Amazon разработала инструмент для идентификации инженеров-программистов, которых она, возможно, захочет принять на работу, но алгоритм включал в себе предвзятые идеи инженеров-мужчин, которые его создали.
В результате, система вскоре начала дискриминацию в отношении женщин, что привело к тому, что в 2017 году компания от нее отказалась.
Совсем недавно, Apple и Goldman Sachs выпустили кредитную карту, которую некоторые обвиняют в сексизме.
Для супружеской пары, которая подает совместную налоговую декларацию и проживает в штатах с режимом общности, алгоритм “черного ящика” Apple предоставил мужу кредитный лимит в 20 раз выше, чем его жене.
<P>
Влияние сознательных или неосознанных преференций создателей алгоритмов может оставаться незамеченным до тех пор, пока они не начнут использоваться, и их встроенные искажения потенциально усилятся.
К счастью, алгоритмы можно пересматривать и отслеживать, чтобы избежать несправедливых результатов.
Например, сотрудник банка может неосознанно учитывать пол заявителя при принятии решения о выдаче кредита.
Ведь при помощи алгоритма вы можете просто исключить гендерную переменную и другие тесно взаимосвязанные факторы при вычислении результатов оценки.
Вот почему так важно применять правильные меры предосторожности при разработке модели.
<P>
Другая большая этическая проблема связана с прозрачностью и “объяснимостью” моделей, управляемых ИИ.
Поскольку эти модели будут все чаще использоваться для принятия решений о найме на работу, кредитовании и, возможно, даже юридических решений, важно знать их важнейшие элементы и относительную значимость каждой из них в процессе принятия решений.
Нам необходимо открыть черный ящик, чтобы понять процессы, процедуры и иногда неявные предположения, которые он содержит.
Регулирование также будет все больше подталкивать нас в этом направлении: например, GDPR вводит право для отдельных лиц получать “важную информацию об используемой привлеченной логике” при автоматизированном принятии решений, которое имеет “юридические или аналогичные последствия”.
<P>
Сегодня, у нас еще больше вопросов, чем ответов относительно технологической устойчивости.
Вероятно, на данный момент это хорошо, потому что мы входим на неизведанную территорию с должным вниманием и осторожностью.
В конце концов, разработка более комплексного подхода к климату и окружающей среде заняла много лет, и нам, вероятно, еще предстоит пройти долгий путь.
Теперь мы должны начать аналогичный путь к технологической устойчивости и задаться вопросом, насколько хорошо мы подготовлены к тому, чтобы обсуждать практические, социальные и этические последствия новых и мощных цифровых инструментов.
<P>
Поскольку эти вопросы затрагивают как антропологию и философию, так и экономику, и политику, мы должны отвечать на них посредством открытых и всеобъемлющих дискуссий, междисциплинарных рамок и хорошо скоординированных коллективных действий.
Эти совместные усилия должны объединить государственный и частный сектор, а также потребителей, сотрудников и инвесторов.
<P>
Хотя технологический прогресс сопряжен с рисками, он в конечном итоге улучшает жизнь каждого.
Путем ответственного управления этими достижениями, мы можем гарантировать, что человечество и цифровая технология объединятся для создания более устойчивого будущего.
